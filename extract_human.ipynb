{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # From tensorflow/models/\n",
    "# protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.path.append('./tensorflow-models/')\n",
    "sys.path.append('./tensorflow-models/object_detection')\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'faster_rcnn_resnet101_coco_11_06_2017'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n",
    "\n",
    "PATH_TO_CKPT = MODEL_NAME + '/frozen_inference_graph.pb'\n",
    "NUM_CLASSES = 90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# opener = urllib.request.URLopener()\n",
    "# opener.retrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n",
    "# tar_file = tarfile.open(MODEL_FILE)\n",
    "# for file in tar_file.getmembers():\n",
    "#     file_name = os.path.basename(file.name)\n",
    "#     if 'frozen_inference_graph.pb' in file_name:\n",
    "#         tar_file.extract(file, os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = np.load('d2/image_train.npz')\n",
    "x_train = train_data['xs']\n",
    "\n",
    "val_data = np.load('d2/image_val.npz')\n",
    "x_val = val_data['xs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_data['ys']\n",
    "y_val = val_data['ys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_human(xs):\n",
    "    with detection_graph.as_default():\n",
    "        with tf.Session(graph=detection_graph) as sess:\n",
    "            image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "            detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "            detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "            detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "            num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
    "\n",
    "        for x in tqdm(xs):\n",
    "            x = x.astype(np.uint8)\n",
    "            (boxes, scores, classes, num) = sess.run(\n",
    "                [detection_boxes, detection_scores, detection_classes, num_detections],\n",
    "                feed_dict={image_tensor: np.expand_dims(x, axis=0)})\n",
    "            \n",
    "            person_indices = classes == 1 # person\n",
    "            score_indices = scores > 0.60\n",
    "            indices = person_indices & score_indices\n",
    "            boxes = boxes[indices]\n",
    "            scores = scores[indices]\n",
    "            classes = classes[indices]\n",
    "            num = indices.sum()\n",
    "            \n",
    "            yield num, boxes, scores\n",
    "            \n",
    "#             vis_util.draw_bounding_boxes_on_image_array(\n",
    "#                 x, \n",
    "#                 np.squeeze(boxes), \n",
    "#                 display_str_list_list=[[f'{x:.2f}'] for x in np.squeeze(scores)], \n",
    "#                 thickness=2)\n",
    "#             plt.figure(figsize=(20, 15))\n",
    "#             plt.imshow(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 42/42 [01:01<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 8, 1, 4, 1, 2, 4, 2, 2, 5, 2, 3, 2, 2, 2, 4, 2, 4, 5, 2, 3, 4, 3, 3, 0, 4, 4, 1, 3, 2, 3, 3, 2, 5, 1, 3, 5, 2, 2, 1, 4, 2]\n"
     ]
    }
   ],
   "source": [
    "hls = list([x_train[i] for i in range(100) if y_train[i] == 1])\n",
    "nums = list(extract_human(hls))\n",
    "print(nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<matplotlib.axes._subplots.AxesSubplot object at 0x000000003C20B240>]], dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEFCAYAAAAsU2YoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3be408d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set(color_codes=True)\n",
    "sns.set(style='white', palette='muted')\n",
    "\n",
    "df = pd.DataFrame(nums, columns=['nums'])\n",
    "df.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 500/500 [11:03<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n"
     ]
    }
   ],
   "source": [
    "N = 500\n",
    "df = pd.DataFrame(index=range(N), columns=['num', 'boxes', 'scores'])\n",
    "for i, (num, boxes, scores) in enumerate(extract_human(x_train[:N])):\n",
    "    df['num'][i] = num\n",
    "    df['boxes'][i] = boxes\n",
    "    df['scores'][i] = scores\n",
    "print((df['num'] < 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tt]",
   "language": "python",
   "name": "conda-env-tt-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
